{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bookmark Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Data/df_website_content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['text'] != 'empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means is used to establish the number of topics ‘k’ that will be passed to LDA.  The number will be determined by increasing k until the highest weighted words in each topic reach the desired level of homogeneity.  Purity will also be assessed based on the content of the documents that are closest to the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sklearn KMeans centers the data but doing normalization explicitly here \n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english', min_df=2, max_df=.95)\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf = normalize(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_models(data, cluster_lst, n_iter, jobs=4):\n",
    "    model_dict = {}\n",
    "    for k in cluster_lst:\n",
    "        model_dict[k] = {}\n",
    "        model = KMeans(n_clusters=k, n_init=n_iter, n_jobs=jobs, random_state=123)\n",
    "        model_dict[k]['model'] = model\n",
    "        model_dict[k]['distances'] = model.fit_transform(tf_idf)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_lst = np.arange(5, 120, 20)\n",
    "k_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "models_dict = build_models(tf_idf, k_lst, 15, 4)\n",
    "end = time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_lst = [abs(models_dict[k]['model'].score(tf_idf)) for k in k_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('K vs. Heterogeneity')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_k_vs_heterogeneity(k_lst, h_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_cluster_counts(k_val, models, ticks=True, logscale=False):\n",
    "    labels = models[k_val]['model'].labels_\n",
    "    g = sns.barplot(x=np.arange(k_val), y=np.bincount(labels))\n",
    "    if not ticks:\n",
    "        g.set(xticklabels=[])\n",
    "    if logscale:\n",
    "        g.figure.get_axes()[0].set_yscale('log')\n",
    "    else: plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the bookmarks are data science, pure math, or finance.  Three major cluster groups make sense in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_cluster_counts(5, models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_cluster_counts(25, models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_cluster_counts(45, models_dict, ticks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying topic themes by top weighted words and doc distance to centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indx_to_word = {v:k for k,v in tf_idf_vectorizer.vocabulary_.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_cluster_words(df, models, word_map, k, n_words, n_docs=5, display_content=False):\n",
    "    #should check if k is valid\n",
    "    centroids = models[k]['model'].cluster_centers_\n",
    "    for c in xrange(len(centroids)):\n",
    "        print('Cluster {0:d}    '.format(c)),\n",
    "        indx = centroids[c].argsort()[::-1]\n",
    "        for i in xrange(n_words):\n",
    "            print('{0:s}:{1:.3f}'.format(word_map[indx[i]].encode('utf-8'), centroids[c, indx[i]])),\n",
    "        print('')\n",
    "        \n",
    "        if display_content:\n",
    "            c_filter = models_dict[k]['model'].labels_ == c\n",
    "            min_cluster_idx = models_dict[k]['distances'][c_filter][:,c].argsort()\n",
    "            cluster_df = df['text'][c_filter]\n",
    "            cluster_df.reset_index(drop=True, inplace=True)\n",
    "            nearest_txt_df = cluster_df.iloc[min_cluster_idx]\n",
    "       \n",
    "            if len(cluster_df) >= n_docs:\n",
    "                for i in xrange(n_docs):\n",
    "                    text = ' '.join(nearest_txt_df.iloc[i].split(None, 25)[0:25]).encode('utf-8')\n",
    "                    print('\\n* {0:s}\\n  {1:s}'.format(\n",
    "                            text[:90], text[90:180] if len(text) > 90 else ''))\n",
    "            else: print(\"not enough docs in group\")\n",
    "        print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_cluster_words(df, models_dict, word_map=indx_to_word, k=25, n_words=6, n_docs=8, display_content=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cluster_words(df, models_dict, indx_to_word, 45, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a cluster count of 45, many of the cluster are pure in content.  However, there are some clusters which have similar themes but are split into different clusters.  A cluster count between 25 and 45 will be use for LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all topics have a clear theme\n",
    "Things to try:\n",
    "try setting max_features in cv (this seemed to help)\n",
    "use graphlab\n",
    "modify alpha and beta in LDA\n",
    "reduce the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(stop_words='english', token_pattern=r'(?u)\\b[a-z\\'A-Z-]{2,}\\b', min_df=2, max_df=.95, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf1 = cv1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_1 = LatentDirichletAllocation(n_topics=25, max_iter=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "lda_1.fit(tf1)\n",
    "print \"done in {0}\".format(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic #%d:\" % topic_idx\n",
    "        print \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_top_words(lda_1, cv.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_word_rank(model, n_top_words):\n",
    "    #topic_sums = np.sum(model.components_, axis=1)\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_nums = [model.components_[idx, i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        #plt.semilogy(range(n_top_words), top_nums)\n",
    "        plt.plot(range(n_top_words), top_nums)\n",
    "    plt.xlabel('Word rank')\n",
    "    plt.ylabel('Word weight')\n",
    "    plt.title('Word Weight of Top 100 Words in each Topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_word_rank(lda_1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_top_words(model, n_top_words):\n",
    "    topic_sums = np.sum(model.components_, axis=1)\n",
    "    doc_probs = []\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_words = [model.components_[idx, i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        doc_probs.append(np.sum(top_words) / topic_sums[idx])\n",
    "    \n",
    "    g= sns.barplot(x=np.arange(len(topic_sums)), y=doc_probs)\n",
    "    g.set(xticklabels=[])\n",
    "    plt.title('Total Probability of Top 10 Words in each Topic')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of the topics, the top 10 word carry most of the weight.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_words(lda_1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[1, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(lda_1.transform(tf1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(lda_1.transform(tf1[0]))[0,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_43 = np.argmax(lda_1.transform(tf1), axis=1) == 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_43 = df[filter_43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_mat = lda_1.transform(tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(lda_mat[filter_43], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_43.loc[2,'text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
